{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f5a36fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pillow\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install opencv-python\n",
    "from numpy import expand_dims\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img,img_to_array,image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c4c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = Rescaling(scale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e52deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17416 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory(\n",
    "    directory='train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(128, 128),\n",
    "    seed=1024\n",
    ")\n",
    "train_ds = train_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "23ec0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2898 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = image_dataset_from_directory(\n",
    "    directory='val',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(128, 128),\n",
    "    seed=1024\n",
    ")\n",
    "val_ds =  val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164f2c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8691 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = image_dataset_from_directory(\n",
    "    directory='test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    image_size=(128, 128),\n",
    "    seed=1024\n",
    ")\n",
    "# test_ds = test_ds.map(lambda image,label:(rescale(image),label,test_ds.file_paths))\n",
    "test_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222332f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model_MobileNet =  MobileNet(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "\n",
    "\n",
    "# for layer in model_MobileNet.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "    # Tạo model với input là ảnh, lấy output của VGG16 và làm input của các layers FC thêm vào\n",
    "output_model_MobileNet = model_MobileNet.output\n",
    "\n",
    "# Thêm vào các FC layers \n",
    "x = Flatten(name='flatten')(output_model_MobileNet)\n",
    "x = Dense(20, activation='sigmoid', name='fc1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(7, activation='softmax', name='predictions')(x)\n",
    "model = Model(model_MobileNet.input, x)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics='accuracy',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4c7d0bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "\n",
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "cb_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoints/MobileNet',\n",
    "    monitor= 'val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=20,\n",
    "                    validation_data = val_ds,\n",
    "                    callbacks=[cb_early_stopping, cb_model_checkpoint,reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a37d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691/8691 [==============================] - 53s 6ms/step - loss: 0.3517 - accuracy: 0.9109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3517066240310669, 0.9109423756599426]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "label = test_ds\n",
    "# for i,k in test_ds:\n",
    "#       print(k)\n",
    "# print(label.info.features)\n",
    "image = load_img('test/df/ISIC_0024330.jpg_10.jpg',target_size=(128,128))\n",
    "image2 =  expand_dims(image, 0)\n",
    "a = model.predict(image2/255)\n",
    "print(a)\n",
    "index = np.argmax(a)\n",
    "print(index)\n",
    "# print(label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e56a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 20)                327700    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 147       \n",
      "=================================================================\n",
      "Total params: 3,556,711\n",
      "Trainable params: 3,534,823\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_load = tf.keras.models.load_model('checkpoints/MobileNet')\n",
    "\n",
    "# Show the model architecture\n",
    "model_load.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28756ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(model_load.input,model_load.get_layer(\"fc1\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa802798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 20)                327700    \n",
      "=================================================================\n",
      "Total params: 3,556,564\n",
      "Trainable params: 3,534,676\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721cfcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 20)                327700    \n",
      "=================================================================\n",
      "Total params: 3,556,564\n",
      "Trainable params: 3,534,676\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_encoder():\n",
    "    return tf.keras.models.Model(new_model.input, new_model.output)\n",
    "\n",
    "model_encoder = build_encoder()\n",
    "model_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35329c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 63, 63, 32)   864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 63, 63, 32)   96          conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 63, 63, 32)   0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 61, 61, 32)   9216        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 61, 61, 32)   96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 61, 61, 32)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 61, 61, 64)   18432       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 61, 61, 64)   192         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 61, 61, 64)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 30, 30, 64)   0           activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 30, 30, 80)   5120        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 30, 30, 80)   240         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 30, 30, 80)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 28, 28, 192)  138240      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 28, 28, 192)  576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 28, 28, 192)  0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 13, 13, 192)  0           activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 13, 13, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 13, 13, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 13, 13, 64)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 13, 13, 48)   9216        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 13, 13, 96)   55296       activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 13, 13, 48)   144         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 13, 13, 96)   288         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 13, 13, 48)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 13, 13, 96)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 13, 13, 192)  0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 13, 13, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 13, 13, 64)   76800       activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 13, 13, 96)   82944       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 13, 13, 32)   6144        average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 13, 13, 64)   192         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 13, 13, 64)   192         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 13, 13, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 13, 13, 32)   96          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 13, 13, 64)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 13, 13, 64)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 13, 13, 96)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 13, 13, 32)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_287[0][0]             \n",
      "                                                                 activation_289[0][0]             \n",
      "                                                                 activation_292[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 13, 13, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 13, 13, 64)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 13, 13, 96)   55296       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 13, 13, 48)   144         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 13, 13, 96)   288         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 13, 13, 48)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 13, 13, 96)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 13, 13, 64)   76800       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 13, 13, 96)   82944       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 13, 13, 64)   16384       average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 13, 13, 64)   192         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 13, 13, 64)   192         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 13, 13, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 13, 13, 64)   192         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 13, 13, 64)   0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 13, 13, 64)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 13, 13, 96)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 13, 13, 64)   0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_294[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_299[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 13, 13, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 13, 13, 64)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 13, 13, 96)   55296       activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 13, 13, 48)   144         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 13, 13, 96)   288         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 13, 13, 48)   0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 13, 13, 96)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 13, 13, 64)   76800       activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 13, 13, 96)   82944       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 13, 13, 64)   18432       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 13, 13, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 13, 13, 64)   192         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 13, 13, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 13, 13, 64)   192         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 13, 13, 64)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 13, 13, 64)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 13, 13, 96)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 13, 13, 64)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_301[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 13, 13, 64)   192         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 13, 13, 64)   0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 13, 13, 96)   55296       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 13, 13, 96)   288         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 13, 13, 96)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 6, 6, 96)     82944       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 6, 6, 384)    1152        conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 6, 6, 96)     288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 6, 6, 384)    0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 6, 6, 96)     0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_308[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 6, 6, 128)    384         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 6, 6, 128)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 6, 6, 128)    114688      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 6, 6, 128)    384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 6, 6, 128)    0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 6, 6, 128)    114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 6, 6, 128)    384         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 6, 6, 128)    384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 6, 6, 128)    0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 6, 6, 128)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 6, 6, 128)    114688      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 6, 6, 128)    114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 6, 6, 128)    384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 6, 6, 128)    384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 6, 6, 128)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 6, 6, 128)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 6, 6, 192)    172032      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 6, 6, 192)    172032      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 6, 6, 192)    576         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 6, 6, 192)    576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 6, 6, 192)    576         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 6, 6, 192)    576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 6, 6, 192)    0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 6, 6, 192)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 6, 6, 192)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 6, 6, 192)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_312[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "                                                                 activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 6, 6, 160)    480         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 6, 6, 160)    0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 6, 6, 160)    179200      activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 6, 6, 160)    480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 6, 6, 160)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 6, 6, 160)    179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 6, 6, 160)    480         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 6, 6, 160)    480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 6, 6, 160)    0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 6, 6, 160)    0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 6, 6, 160)    179200      activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 6, 6, 160)    179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 6, 6, 160)    480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 6, 6, 160)    480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 6, 6, 160)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 6, 6, 160)    0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 6, 6, 192)    215040      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 6, 6, 192)    215040      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 6, 6, 192)    576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 6, 6, 192)    576         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 6, 6, 192)    576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 6, 6, 192)    576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 6, 6, 192)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 6, 6, 192)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 6, 6, 192)    0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 6, 6, 192)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_322[0][0]             \n",
      "                                                                 activation_325[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 6, 6, 160)    480         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 6, 6, 160)    0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 6, 6, 160)    179200      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 6, 6, 160)    480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 6, 6, 160)    0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 6, 6, 160)    179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 6, 6, 160)    480         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 6, 6, 160)    480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 6, 6, 160)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 6, 6, 160)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 6, 6, 160)    179200      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 6, 6, 160)    179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 6, 6, 160)    480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 6, 6, 160)    480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 6, 6, 160)    0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 6, 6, 160)    0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 6, 6, 192)    215040      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 6, 6, 192)    215040      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 6, 6, 192)    576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 6, 6, 192)    576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 6, 6, 192)    576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 6, 6, 192)    576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 6, 6, 192)    0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 6, 6, 192)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 6, 6, 192)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 6, 6, 192)    0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_332[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 6, 6, 192)    576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 6, 6, 192)    0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 6, 6, 192)    258048      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 6, 6, 192)    576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 6, 6, 192)    0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 6, 6, 192)    258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 6, 6, 192)    576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 6, 6, 192)    576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 6, 6, 192)    0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 6, 6, 192)    0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 6, 6, 192)    258048      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 6, 6, 192)    258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 6, 6, 192)    576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 6, 6, 192)    576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 6, 6, 192)    0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 6, 6, 192)    0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 6, 6, 192)    258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 6, 6, 192)    258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 6, 6, 192)    576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 6, 6, 192)    576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 6, 6, 192)    576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 6, 6, 192)    576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 6, 6, 192)    0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 6, 6, 192)    0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 6, 6, 192)    0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 6, 6, 192)    0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_342[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 6, 6, 192)    576         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 6, 6, 192)    0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 6, 6, 192)    258048      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 6, 6, 192)    576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 6, 6, 192)    0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 6, 6, 192)    258048      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 6, 6, 192)    576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 6, 6, 192)    576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 6, 6, 192)    0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 6, 6, 192)    0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 2, 2, 320)    552960      activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 2, 2, 192)    331776      activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 2, 2, 320)    960         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 2, 2, 192)    576         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 2, 2, 320)    0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 2, 2, 192)    0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_353[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 2, 2, 448)    1344        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 2, 2, 448)    0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 2, 2, 384)    1548288     activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 2, 2, 384)    1152        conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 2, 2, 384)    1152        conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 2, 2, 384)    0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 2, 2, 384)    0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 2, 2, 384)    442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 2, 2, 384)    442368      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 2, 2, 384)    442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 2, 2, 384)    442368      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 2, 2, 384)    1152        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 2, 2, 384)    1152        conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 2, 2, 384)    1152        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 2, 2, 384)    1152        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 2, 2, 192)    245760      average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 2, 2, 320)    960         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 2, 2, 384)    0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 2, 2, 384)    0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 2, 2, 384)    0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 2, 2, 384)    0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 2, 2, 192)    576         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 2, 2, 320)    0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_360[0][0]             \n",
      "                                                                 activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2, 2, 768)    0           activation_364[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 2, 2, 192)    0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_358[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 2, 2, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 2, 2, 448)    1344        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 2, 2, 448)    0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 2, 2, 384)    1548288     activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 2, 2, 384)    1152        conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 2, 2, 384)    1152        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 2, 2, 384)    0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 2, 2, 384)    0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 2, 2, 384)    442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 2, 2, 384)    442368      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 2, 2, 384)    442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 2, 2, 384)    442368      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, 2, 2, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 2, 2, 384)    1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 2, 2, 384)    1152        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 2, 2, 384)    1152        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 2, 2, 384)    1152        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 2, 2, 192)    393216      average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 2, 2, 320)    960         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 2, 2, 384)    0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 2, 2, 384)    0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 2, 2, 384)    0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 2, 2, 384)    0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 2, 2, 192)    576         conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 2, 2, 320)    0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 2, 2, 768)    0           activation_369[0][0]             \n",
      "                                                                 activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2, 2, 768)    0           activation_373[0][0]             \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 2, 2, 192)    0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 2, 2, 2048)   0           activation_367[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 20)           163860      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 20)           0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 7)            147         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,966,791\n",
      "Trainable params: 21,932,359\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_load_InceptionV3 = tf.keras.models.load_model('checkpoints/InceptionV3')\n",
    "\n",
    "# Show the model architecture\n",
    "model_load_InceptionV3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a5096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionV3 = Model(model_load_InceptionV3.input,model_load_InceptionV3.get_layer(\"fc1\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0808b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 20)                163860    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 147       \n",
      "=================================================================\n",
      "Total params: 14,878,695\n",
      "Trainable params: 14,878,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_load_VGG16 = tf.keras.models.load_model('checkpoints/VGG16')\n",
    "\n",
    "# Show the model architecture\n",
    "model_load_VGG16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75887fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG16 = Model(model_load_VGG16.input,model_load_VGG16.get_layer(\"fc1\").output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d2aafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_VGG16 = []\n",
    "\n",
    "train_image_inceptionV3 = []\n",
    "train_image_mobilenet = []\n",
    "train_label_mobilenet = []\n",
    "\n",
    "\n",
    "for img,labels in train_ds:\n",
    "    train_image_inceptionV3.append(model_inceptionV3.predict(img).flatten())\n",
    "    train_image_VGG16.append(model_VGG16.predict(img).flatten())\n",
    "    train_image_mobilenet.append(model_encoder.predict(img).flatten())\n",
    "    train_label_mobilenet.append(np.argmax(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce1d0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix = []\n",
    "for i in range(0,len(train_label_mobilenet)):\n",
    "    train_mix.append(np.concatenate((train_image_inceptionV3[i], train_image_VGG16[i],train_image_mobilenet[i]), axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "315357dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 17416\n"
     ]
    }
   ],
   "source": [
    "print(len(train_mix[0]),len(train_label_mobilenet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0191ec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=128)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=128)\n",
    "clf.fit(train_mix,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dd82c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.dump(clf,\"randomForest128_cnn_mix.pkl\")\n",
    "# result = loaded_model.score(train_image_embeddings, train_labels)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313e7480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X = []\n",
    "# test_Y = []\n",
    "# for img,labels in test_ds:\n",
    "#     test_X.append(model_encoder.predict(img).flatten())\n",
    "#     test_Y.append(np.argmax(labels));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4afc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_VGG16 = []\n",
    "\n",
    "test_image_inceptionV3 = []\n",
    "test_image_mobilenet = []\n",
    "test_label_mobilenet = []\n",
    "\n",
    "\n",
    "for img,labels in test_ds:\n",
    "    test_image_VGG16.append(model_inceptionV3.predict(img).flatten())\n",
    "    test_image_inceptionV3.append(model_VGG16.predict(img).flatten())\n",
    "    test_image_mobilenet.append(model_encoder.predict(img).flatten())\n",
    "    test_label_mobilenet.append(np.argmax(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ca0af8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_2 =SVC(kernel='linear')\n",
    "clf_2.fit(train_mix,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "45bc4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.dump(clf_2,\"SVM_cnn_mix.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c02f3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mix = []\n",
    "for i in range(0,len(test_label_mobilenet)):\n",
    "    test_mix.append(np.concatenate((test_image_inceptionV3[i], test_image_VGG16[i],test_image_mobilenet[i]), axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "28f27c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9017374295247957\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_mix, test_label_mobilenet))  # randomForest 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26018bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458290185249108\n"
     ]
    }
   ],
   "source": [
    "print(clf_2.score(test_mix, test_label_mobilenet))  # SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fe4b1184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1024)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1024)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=1024)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "clf_3 = RandomForestClassifier(n_estimators=1024)\n",
    "clf_3.fit(train_mix,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6ffc281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9024277988723968\n"
     ]
    }
   ],
   "source": [
    "print(clf_3.score(test_mix, test_label_mobilenet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7727f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install seaborn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "target_names = ['akiec','bcc','bkl','df','mel','nv','vasc'] \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt='', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48429e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cm1, annot=True, fmt='.4f', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecba8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- Mix MobileNet and InceptionV3 -------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8c79c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix_2 = []\n",
    "for i in range(0,len(train_label_mobilenet)):\n",
    "    train_mix_2.append(np.concatenate((train_image_mobilenet[i],train_image_inceptionV3[i]), axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8a5ef830",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mix_2 = []\n",
    "for i in range(0,len(test_label_mobilenet)):\n",
    "    test_mix_2.append(np.concatenate((test_image_mobilenet[i],test_image_inceptionV3[i]), axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f216c973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=128)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mix_2_1 = RandomForestClassifier(n_estimators=128)\n",
    "clf_mix_2_1.fit(train_mix_2,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9706e26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046139684731331\n"
     ]
    }
   ],
   "source": [
    "print(clf_mix_2_1.score(test_mix_2, test_label_mobilenet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9007a538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mix_2_2 = SVC(kernel='linear')\n",
    "clf_mix_2_2.fit(train_mix_2,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8216d042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9002416292716603\n"
     ]
    }
   ],
   "source": [
    "print(clf_mix_2_2.score(test_mix_2, test_label_mobilenet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- Mix MobileNet and VGG16 -------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d4b0b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix_3 = []\n",
    "for i in range(0,len(train_label_mobilenet)):\n",
    "    train_mix_3.append(np.concatenate((train_image_mobilenet[i],train_image_VGG16[i]), axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5296a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mix_3 = []\n",
    "for i in range(0,len(test_label_mobilenet)):\n",
    "    test_mix_3.append(np.concatenate((test_image_mobilenet[i],test_image_VGG16[i]), axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "97f98f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=128)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mix_3_1 = RandomForestClassifier(n_estimators=128)\n",
    "clf_mix_3_1.fit(train_mix_3,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "92e96206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9059947071683351\n"
     ]
    }
   ],
   "source": [
    "print(clf_mix_3_1.score(test_mix_3, test_label_mobilenet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a963705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;background-color: white;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" checked><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mix_3_2 = SVC(kernel='linear')\n",
    "clf_mix_3_2.fit(train_mix_3,  train_label_mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f4c5acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9024277988723968\n"
     ]
    }
   ],
   "source": [
    "print(clf_mix_3_2.score(test_mix_3, test_label_mobilenet)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fea8c4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17416, 40)\n",
      "(17416,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_mix_3).shape)\n",
    "print(np.array(train_label_mobilenet).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7eb24fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_VGG16_MLP = []\n",
    "\n",
    "train_image_inceptionV3_MLP = []\n",
    "train_image_mobilenet_MLP = []\n",
    "train_label_mobilenet_MLP = []\n",
    "\n",
    "for img,labels in train_ds:\n",
    "    train_image_inceptionV3_MLP.append(model_inceptionV3.predict(img).flatten())\n",
    "    train_image_VGG16_MLP.append(model_VGG16.predict(img).flatten())\n",
    "    train_image_mobilenet_MLP.append(model_encoder.predict(img).flatten())\n",
    "    train_label_mobilenet_MLP.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5a0b73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_VGG16_MLP = []\n",
    "\n",
    "val_image_inceptionV3_MLP = []\n",
    "val_image_mobilenet_MLP = []\n",
    "val_label_mobilenet_MLP = []\n",
    "\n",
    "for img,labels in val_ds:\n",
    "    val_image_inceptionV3_MLP.append(model_inceptionV3.predict(img).flatten())\n",
    "    val_image_VGG16_MLP.append(model_VGG16.predict(img).flatten())\n",
    "    val_image_mobilenet_MLP.append(model_encoder.predict(img).flatten())\n",
    "    val_label_mobilenet_MLP.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "72240ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_mobilenet_MLP_re = np.array(val_label_mobilenet_MLP).reshape((-1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b6c516b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_VGG16_MLP = []\n",
    "\n",
    "test_image_inceptionV3_MLP = []\n",
    "test_image_mobilenet_MLP = []\n",
    "test_label_mobilenet_MLP = []\n",
    "\n",
    "for img,labels in test_ds:\n",
    "    test_image_inceptionV3_MLP.append(model_inceptionV3.predict(img).flatten())\n",
    "    test_image_VGG16_MLP.append(model_VGG16.predict(img).flatten())\n",
    "    test_image_mobilenet_MLP.append(model_encoder.predict(img).flatten())\n",
    "    test_label_mobilenet_MLP.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "51d31878",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_mobilenet_MLP_re = np.array(test_label_mobilenet_MLP).reshape((-1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e394e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix_3 = []\n",
    "for i in range(0,len(train_label_mobilenet_MLP)):\n",
    "    train_mix_3.append(np.concatenate((train_image_mobilenet_MLP[i],train_image_VGG16_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "07ebd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mix_3 = []\n",
    "for i in range(0,len(val_label_mobilenet_MLP)):\n",
    "    val_mix_3.append(np.concatenate((val_image_mobilenet_MLP[i],val_image_VGG16_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2038b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mix_3 = []\n",
    "for i in range(0,len(test_label_mobilenet_MLP_re)):\n",
    "    test_mix_3.append(np.concatenate((test_image_mobilenet_MLP[i],test_image_VGG16_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d3073b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691\n"
     ]
    }
   ],
   "source": [
    "print(len(test_mix_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5e53825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17416, 40)\n",
      "(17416, 7)\n"
     ]
    }
   ],
   "source": [
    "train_label_mobilenet_MLP_re = np.array(train_label_mobilenet_MLP).reshape((-1,7))\n",
    "for i in train_label_mobilenet_MLP_re:\n",
    "    print(np.array(train_mix_3).shape)\n",
    "    print(tf.stack(train_label_mobilenet_MLP_re).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "fd91d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 224)               9184      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 7)                 1575      \n",
      "=================================================================\n",
      "Total params: 10,759\n",
      "Trainable params: 10,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(224,input_dim=40,activation=\"sigmoid\"))\n",
    "mlp.add(Dropout(0.2))\n",
    "mlp.add(Dense(7,activation=\"softmax\"))\n",
    "mlp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics='accuracy',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "mlp.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c51a8824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.9992 - val_loss: 0.2549 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25487, saving model to checkpoints\\MLP_mobileNet_Vgg16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_Vgg16\\assets\n",
      "Epoch 2/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9993 - val_loss: 0.2570 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.25487\n",
      "Epoch 3/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9991 - val_loss: 0.2591 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25487\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 4/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.2604 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25487\n",
      "Epoch 5/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.2617 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25487\n",
      "Epoch 6/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.2632 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25487\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "\n",
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "cb_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoints/MLP_mobileNet_Vgg16',\n",
    "    monitor= 'val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "history = mlp.fit(np.array(train_mix_3),tf.stack(train_label_mobilenet_MLP_re),batch_size=64,\n",
    "                      validation_data=(np.array(val_mix_3),val_label_mobilenet_MLP_re),\n",
    "                    epochs=50,\n",
    "                    callbacks=[cb_early_stopping, cb_model_checkpoint,reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "94fd6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691/8691 [==============================] - 15s 2ms/step - loss: 0.2480 - accuracy: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24795357882976532, 0.9305028319358826]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.evaluate(np.array(test_mix_3),test_label_mobilenet_MLP_re,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Mix mobileNet and InceptionV3 MLP ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "d1a24b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix_4 = []\n",
    "for i in range(0,len(train_label_mobilenet_MLP)):\n",
    "    train_mix_4.append(np.concatenate((train_image_mobilenet_MLP[i],train_image_inceptionV3_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "07840c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mix_4 = []\n",
    "for i in range(0,len(val_label_mobilenet_MLP)):\n",
    "    val_mix_4.append(np.concatenate((val_image_mobilenet_MLP[i],val_image_inceptionV3_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "e04601d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mix_4 = []\n",
    "for i in range(0,len(test_label_mobilenet_MLP_re)):\n",
    "    test_mix_4.append(np.concatenate((test_image_mobilenet_MLP[i],test_image_inceptionV3_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "db6d8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 224)               9184      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 7)                 1575      \n",
      "=================================================================\n",
      "Total params: 10,759\n",
      "Trainable params: 10,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp4 = Sequential()\n",
    "mlp4.add(Dense(224,input_dim=40,activation=\"sigmoid\"))\n",
    "mlp4.add(Dropout(0.2))\n",
    "mlp4.add(Dense(7,activation=\"softmax\"))\n",
    "mlp4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics='accuracy',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "mlp4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "af959e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9996 - val_loss: 0.2712 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27123, saving model to checkpoints\\MLP_mobileNet_InceptionV3\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3\\assets\n",
      "Epoch 2/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9996 - val_loss: 0.2718 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27123\n",
      "Epoch 3/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9997 - val_loss: 0.2722 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27123\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 4/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9996 - val_loss: 0.2728 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27123\n",
      "Epoch 5/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 0.2731 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27123\n",
      "Epoch 6/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9997 - val_loss: 0.2740 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27123\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "cb_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoints/MLP_mobileNet_InceptionV3',\n",
    "    monitor= 'val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "history = mlp4.fit(np.array(train_mix_4),tf.stack(train_label_mobilenet_MLP_re),batch_size=64,\n",
    "                      validation_data=(np.array(val_mix_4),val_label_mobilenet_MLP_re),\n",
    "                    epochs=50,\n",
    "                    callbacks=[cb_early_stopping, cb_model_checkpoint,reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "d8fb7421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691/8691 [==============================] - 15s 2ms/step - loss: 0.2520 - accuracy: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.252002477645874, 0.9301576614379883]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4.evaluate(np.array(test_mix_4),test_label_mobilenet_MLP_re,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed857f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Mix mobileNet and  InceptionV3 and VGG16 and MLP ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "8caaa223",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix_5 = []\n",
    "for i in range(0,len(train_label_mobilenet_MLP)):\n",
    "    train_mix_5.append(np.concatenate((train_image_mobilenet_MLP[i],train_image_inceptionV3_MLP[i],train_image_VGG16_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "911c9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mix_5 = []\n",
    "for i in range(0,len(val_label_mobilenet_MLP)):\n",
    "    val_mix_5.append(np.concatenate((val_image_mobilenet_MLP[i],val_image_inceptionV3_MLP[i],val_image_VGG16_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "1fe920fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mix_5 = []\n",
    "for i in range(0,len(test_label_mobilenet_MLP_re)):\n",
    "    test_mix_5.append(np.concatenate((test_image_mobilenet_MLP[i],test_image_inceptionV3_MLP[i],test_image_VGG16_MLP[i]),axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "9e72635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(train_mix_5[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "87e71215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 2401)              146461    \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 2401)              0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 7)                 16814     \n",
      "=================================================================\n",
      "Total params: 163,275\n",
      "Trainable params: 163,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp5 = Sequential()\n",
    "mlp5.add(Dense(224,input_dim=60,activation=\"sigmoid\"))\n",
    "mlp5.add(Dropout(0.2))\n",
    "mlp5.add(Dense(7,activation=\"softmax\"))\n",
    "mlp5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics='accuracy',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "mlp5.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "e14f5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 1.2905 - accuracy: 0.7219 - val_loss: 0.7926 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79261, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 2/50\n",
      "273/273 [==============================] - 1s 2ms/step - loss: 0.4223 - accuracy: 0.9983 - val_loss: 0.3912 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79261 to 0.39118, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 3/50\n",
      "273/273 [==============================] - 1s 2ms/step - loss: 0.1649 - accuracy: 0.9994 - val_loss: 0.2746 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39118 to 0.27462, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 4/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9995 - val_loss: 0.2344 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27462 to 0.23437, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 5/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0494 - accuracy: 0.9997 - val_loss: 0.2172 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23437 to 0.21720, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 6/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9999 - val_loss: 0.2097 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21720 to 0.20966, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 7/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9998 - val_loss: 0.2066 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20966 to 0.20663, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16\\assets\n",
      "Epoch 8/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9998 - val_loss: 0.2067 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20663\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 9/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9997 - val_loss: 0.2067 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20663\n",
      "Epoch 10/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9998 - val_loss: 0.2078 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20663\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 11/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9997 - val_loss: 0.2081 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20663\n",
      "Epoch 12/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9998 - val_loss: 0.2086 - val_accuracy: 0.9379\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20663\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "cb_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoints/MLP_mobileNet_InceptionV3_VGG16',\n",
    "    monitor= 'val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "history = mlp5.fit(np.array(train_mix_5),tf.stack(train_label_mobilenet_MLP_re),batch_size=64,\n",
    "                      validation_data=(np.array(val_mix_5),val_label_mobilenet_MLP_re),\n",
    "                    epochs=50,\n",
    "                    callbacks=[cb_early_stopping, cb_model_checkpoint,reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "69eddcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691/8691 [==============================] - 14s 2ms/step - loss: 0.1983 - accuracy: 0.9424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19833913445472717, 0.942354142665863]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp5.evaluate(np.array(test_mix_5),test_label_mobilenet_MLP_re,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "21ee66ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_241 (Dense)            (None, 1407)              85827     \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 1407)              0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 7)                 9856      \n",
      "=================================================================\n",
      "Total params: 95,683\n",
      "Trainable params: 95,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp6 = Sequential()\n",
    "mlp6.add(Dense(1407,input_dim=60,activation=\"sigmoid\"))\n",
    "mlp6.add(Dropout(0.2))\n",
    "mlp6.add(Dense(7,activation=\"softmax\"))\n",
    "mlp6.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics='accuracy',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "mlp6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "a497795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.9674 - accuracy: 0.8377 - val_loss: 0.4827 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48265, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\\assets\n",
      "Epoch 2/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.1818 - accuracy: 0.9995 - val_loss: 0.2646 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48265 to 0.26463, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\\assets\n",
      "Epoch 3/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9997 - val_loss: 0.2220 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26463 to 0.22200, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\\assets\n",
      "Epoch 4/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9997 - val_loss: 0.2104 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22200 to 0.21039, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\\assets\n",
      "Epoch 5/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9997 - val_loss: 0.2072 - val_accuracy: 0.9379\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21039 to 0.20720, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\\assets\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 6/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9997 - val_loss: 0.2066 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20720 to 0.20657, saving model to checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\n",
      "INFO:tensorflow:Assets written to: checkpoints\\MLP_mobileNet_InceptionV3_VGG16_2\\assets\n",
      "Epoch 7/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9997 - val_loss: 0.2072 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20657\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 8/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9998 - val_loss: 0.2078 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20657\n",
      "Epoch 9/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9998 - val_loss: 0.2088 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20657\n",
      "Epoch 10/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9998 - val_loss: 0.2092 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20657\n",
      "Epoch 11/50\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9997 - val_loss: 0.2105 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20657\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "cb_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=1e-4,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "cb_model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoints/MLP_mobileNet_InceptionV3_VGG16_2',\n",
    "    monitor= 'val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "history = mlp6.fit(np.array(train_mix_5),tf.stack(train_label_mobilenet_MLP_re),batch_size=64,\n",
    "                      validation_data=(np.array(val_mix_5),val_label_mobilenet_MLP_re),\n",
    "                    epochs=50,\n",
    "                    callbacks=[cb_early_stopping, cb_model_checkpoint,reduce_lr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "233c87b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691/8691 [==============================] - 15s 2ms/step - loss: 0.2012 - accuracy: 0.9427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20117460191249847, 0.9426993727684021]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp6.evaluate(np.array(test_mix_5),test_label_mobilenet_MLP_re,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feaf7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (main, Dec 23 2022, 09:25:32) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
